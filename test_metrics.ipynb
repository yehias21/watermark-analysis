{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watermarks.Rivagan import Rivagan\n",
    "from watermarks.StegaStamp import StegaStamp\n",
    "from watermarks.DwtDct import DwtDCT\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import stats\n",
    "import argparse\n",
    "\n",
    "class WatermarkDecoder:\n",
    "    def __init__(self, watermark_algorithm='rivagan', batch_size=16, num_workers=24):\n",
    "        self.watermark_algorithm = watermark_algorithm\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.watermark_key = self._initialize_watermark()\n",
    "        \n",
    "    def _initialize_watermark(self):\n",
    "        if self.watermark_algorithm == 'rivagan':\n",
    "            return Rivagan()\n",
    "        elif self.watermark_algorithm == 'stegastamp':\n",
    "            return StegaStamp()\n",
    "        elif self.watermark_algorithm == 'dwtdct':\n",
    "            return DwtDCT(use_svd=False)\n",
    "        elif self.watermark_algorithm == 'dwtdctsvd':\n",
    "            return DwtDCT(use_svd=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_single_image(image_path):\n",
    "        return Image.open(image_path)\n",
    "\n",
    "    def load_dataset(self, images_path, csv_path):\n",
    "        csv_file = os.path.join(csv_path, 'messages.csv')\n",
    "        data = pd.read_csv(csv_file)\n",
    "        \n",
    "        images_paths = [os.path.join(images_path, f'data_{idx}.png') for idx in data['index']]\n",
    "        \n",
    "        def load_image_set(paths):\n",
    "            with ThreadPoolExecutor(max_workers=self.num_workers) as executor:\n",
    "                images = list(tqdm(\n",
    "                    executor.map(lambda p: self.load_single_image(p), paths),\n",
    "                    total=len(paths),\n",
    "                    desc=\"Loading images\"\n",
    "                ))\n",
    "            return images\n",
    "        \n",
    "        print(\"Loading images...\")\n",
    "        target_images = load_image_set(images_paths)\n",
    "        messages = torch.tensor([eval(m) for m in data['message']])\n",
    "        \n",
    "        return target_images, messages\n",
    "    \n",
    "    def calculate_metrics(self, true_messages, decoded_messages, decoded_probs):\n",
    "        true_messages = true_messages.cpu()\n",
    "        decoded_messages = decoded_messages.cpu()\n",
    "        decoded_probs = decoded_probs.cpu() \n",
    "        \n",
    "        # Calculate overall bit error rate\n",
    "        bit_error_rate = float(torch.mean((true_messages != decoded_messages).float()))\n",
    "        \n",
    "        # Calculate number of correct bits per message\n",
    "        correct_bits_per_message = torch.sum((true_messages == decoded_messages).float(), dim=-1)\n",
    "        message_length = true_messages.shape[-1] \n",
    "        \n",
    "        # Calculate critical values for both alpha levels\n",
    "        critical_value_05 = stats.binom.ppf(1 - 0.05, message_length, 0.5)\n",
    "        critical_value_01 = stats.binom.ppf(1 - 0.01, message_length, 0.5)\n",
    "        \n",
    "        # Calculate accuracy for both thresholds\n",
    "        significant_messages_05 = (correct_bits_per_message > critical_value_05).float()\n",
    "        significant_messages_01 = (correct_bits_per_message > critical_value_01).float()\n",
    "        \n",
    "        accuracy_threshold_05 = float(torch.mean(significant_messages_05))\n",
    "        accuracy_threshold_01 = float(torch.mean(significant_messages_01))\n",
    "        \n",
    "        metrics = {\n",
    "            'bit_error_rate': bit_error_rate,\n",
    "            'accuracy_threshold_0.05': accuracy_threshold_05,\n",
    "            'accuracy_threshold_0.01': accuracy_threshold_01,\n",
    "            'critical_bits_threshold_0.05': float(critical_value_05),\n",
    "            'critical_bits_threshold_0.01': float(critical_value_01),\n",
    "            'allowed_error_bits_0.05': float(message_length - critical_value_05),\n",
    "            'allowed_error_bits_0.01': float(message_length - critical_value_01)\n",
    "        }\n",
    "        \n",
    "        metrics['auc_roc'] = float(roc_auc_score(\n",
    "            true_messages.flatten().numpy(),\n",
    "            decoded_probs.flatten().numpy()\n",
    "        ))\n",
    "        \n",
    "        return metrics, correct_bits_per_message\n",
    "\n",
    "    def test_decoding(self, images_path, csv_path):\n",
    "        target_images, messages = self.load_dataset(images_path, csv_path)\n",
    "        num_batches = len(target_images) // self.batch_size\n",
    "        decoded_messages = []\n",
    "        decoded_probs = []\n",
    "        for i in range(num_batches):\n",
    "            batch_images = target_images[i*self.batch_size:(i+1)*self.batch_size]\n",
    "            print(f\"Batch {i+1}/{num_batches}\")\n",
    "            decoded_prob = self.watermark_key.decode(batch_images)\n",
    "            decoded_messages.append(decoded_prob >= 0.5)\n",
    "            decoded_probs.append(decoded_prob)\n",
    "        \n",
    "        decoded_messages = torch.from_numpy(np.stack(decoded_messages))\n",
    "        decoded_probs = torch.from_numpy(np.stack(decoded_probs))\n",
    "        messages = messages.view(num_batches, self.batch_size, -1)\n",
    "        \n",
    "        # Unpack the tuple returned by calculate_metrics\n",
    "        metrics, correct_bits = self.calculate_metrics(messages, decoded_messages, decoded_probs)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(\"\\nPerformance Metrics:\")\n",
    "        print(\"-\" * 50)\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"{metric_name.replace('_', ' ').title()}: {value:.4f}\")\n",
    "        \n",
    "        return metrics, correct_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/ephemeral/tbakr/watermark-analysis/attacked/1/bmshj2018_hyperprior'\n",
    "metrics_df = pd.DataFrame({'lol':'a7a'}, index=[0])\n",
    "os.makedirs('./performance', exist_ok=True)\n",
    "x =  \n",
    "new_out = os.path.join('./performance', x)\n",
    "metrics_df.to_csv(new_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Test watermark decoding on images')\n",
    "    parser.add_argument('--images_path', type=str, required=True, help='Path to the images folder')\n",
    "    parser.add_argument('--csv_path', type=str, required=True, help='Path to the CSV folder')\n",
    "    parser.add_argument('--algorithm', type=str, required=True,\n",
    "                       choices=['rivagan', 'stegastamp', 'dwtdct', 'dwtdctsvd'],\n",
    "                       help='Watermark algorithm to use')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    decoder = WatermarkDecoder(\n",
    "        watermark_algorithm=args.algorithm,\n",
    "        batch_size=16,\n",
    "        num_workers=24,\n",
    "    )\n",
    "    \n",
    "    metrics, correct_bits = decoder.test_decoding(args.images_path, args.csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada-waves",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
